<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"ColabTrainModel.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8WrUuZChPZe","executionInfo":{"status":"ok","timestamp":1621791440605,"user_tz":-120,"elapsed":909,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"c015e1ba-a731-4e6f-f110-775ab3f707e2"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuWFMg8-hPZg","executionInfo":{"status":"ok","timestamp":1621791449860,"user_tz":-120,"elapsed":9257,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"d2d38a16-e7bf-4174-b61b-8852378ef536"},"source":["!pip install tiffile\n","\n","\n","!pip install gputools\n","\n","!pip install imagecodecs\n","!pip install vollseg\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tiffile in /usr/local/lib/python3.7/dist-packages (2018.10.18)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from tiffile) (2021.4.8)\n","Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from tifffile->tiffile) (1.19.5)\n","Requirement already satisfied: gputools in /usr/local/lib/python3.7/dist-packages (0.2.10)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from gputools) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gputools) (1.15.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gputools) (1.4.1)\n","Requirement already satisfied: reikna>=0.6.7 in /usr/local/lib/python3.7/dist-packages (from gputools) (0.7.5)\n","Requirement already satisfied: pyopencl>=2016.1 in /usr/local/lib/python3.7/dist-packages (from gputools) (2021.2.2)\n","Requirement already satisfied: configparser; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from gputools) (5.0.2)\n","Requirement already satisfied: funcsigs>=0.3 in /usr/local/lib/python3.7/dist-packages (from reikna>=0.6.7->gputools) (1.0.2)\n","Requirement already satisfied: mako>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from reikna>=0.6.7->gputools) (1.1.4)\n","Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyopencl>=2016.1->gputools) (1.4.4)\n","Requirement already satisfied: pytools>=2017.6 in /usr/local/lib/python3.7/dist-packages (from pyopencl>=2016.1->gputools) (2021.2.6)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako>=0.8.0->reikna>=0.6.7->gputools) (2.0.0)\n","Requirement already satisfied: imagecodecs in /usr/local/lib/python3.7/dist-packages (2021.5.20)\n","Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.19.5)\n","Requirement already satisfied: vollseg in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.19.5)\n","Requirement already satisfied: csbdeep in /usr/local/lib/python3.7/dist-packages (from vollseg) (0.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.1.5)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from vollseg) (2021.4.8)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from vollseg) (3.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from vollseg) (0.16.2)\n","Requirement already satisfied: stardist in /usr/local/lib/python3.7/dist-packages (from vollseg) (0.6.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.4.1)\n","Requirement already satisfied: h5py<3 in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (2.10.0)\n","Requirement already satisfied: keras<2.4,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (2.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (4.41.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->vollseg) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->vollseg) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (1.3.1)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (1.1.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (7.1.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (2.5.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from stardist->vollseg) (0.51.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep->vollseg) (1.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep->vollseg) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep->vollseg) (1.0.8)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->vollseg) (4.4.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->stardist->vollseg) (56.1.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->stardist->vollseg) (0.34.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNKAD9UkhPZh","executionInfo":{"status":"ok","timestamp":1621791451940,"user_tz":-120,"elapsed":2094,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"cdfe243d-5b20-4b8a-b8c1-5fcfca480cb8"},"source":["%cd '/content/drive/My Drive/VollSeg/'\n","import os\n","import glob\n","import sys\n","import numpy as np\n","from tqdm import tqdm\n","from tifffile import imread, imwrite\n","from pathlib import Path\n","from vollseg import SmartSeeds3D\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/VollSeg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z5yD4cofhPZh"},"source":["# In the cell below specify the following:\n","\n","1) Directory where the training data is, inside this directory there should be the two subfolders called Raw and Mask. Inside the Raw folder are the raw images and inside the Mask folder are the labelled images.\n","\n","2) The training data for doing UNET training is stored in NPZ format so please specify the NPZ filename which is suitable for your data.\n","\n","3) Model directory is where the trained Neural network models are stored, please chooose a location if you want to change the default location which is where the training data is.\n","\n","4) Copy Model name is optional, in case you have a previouis trained model and want to re-train it on new data but store it with a new name.\n","\n","5) Model name is the unique name of the trained models."]},{"cell_type":"code","metadata":{"id":"Vri8MgwShPZh","executionInfo":{"status":"ok","timestamp":1621791451941,"user_tz":-120,"elapsed":13,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":["Data_dir = '/content/drive/My Drive/data/'\n","NPZ_filename = 'VolumeSeg'\n","Model_dir = '/content/drive/My Drive/data/'\n","Model_Name = 'VolumeSeg'"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqnKEJlUhPZi"},"source":["# In this cell choose the network training parameters for the Neural Network\n","\n","1) NetworkDepth = Depth of the network, with each increasing depth the image is downsampled by 2 hence the XYZ dimension of the data / 2^depth has to be greater than 1.\n","\n","2) Epochs, training for longer epochs ensures a well converged network and requires longer GPU runtimes.\n","\n","3) Learning rate is the parameter which controls the step size used in the optimization process and it should not be greater than 0.001 at the start of the training.\n","\n","4) batch size controls the number of images used for doing stochastic gradient descent and is a parameter that is limited by the GPU RAM available, if you do not have a lot of ran batch size < 10 should be optimal. \n","\n","5) PatchX,Y,Z is the patch size used for making patches out of the iamge data. The original image is broken down into patches for training. Patch size is chosen based on having enough context for the network to learn but at the same time not being too big to obscure memory usage.\n","\n","6) Kernel is the receptive field of the neural network, usual choices are 3,5 or 7 but not larger than that. This is the size of the convolutional kernel used in the network\n","\n","7) n_patches_per_image is the number of patches sampled for each image to create the npz file, choose an optimal value so that the file is not too big for the computer memory. \n","\n","8) Rays is the number of rays used the learn the distance map, low rays decreases the spatial resoultion and high rays are able to resolve the shape better.\n","\n","\n","9) OpenCL is a boolean parameter that is set true if you want to do some opencl computations on the GPU, this requires GPU tools but if you do not have them set this to false.\n","\n","Some optimal values have been chosen by default and should work well for any NVDIA enabled GPU computer"]},{"cell_type":"code","metadata":{"id":"Sh-WQOu7hPZi","executionInfo":{"status":"ok","timestamp":1621791451941,"user_tz":-120,"elapsed":13,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":["#Network training parameters\n","NetworkDepth = 3\n","Epochs = 100\n","LearningRate = 1.0E-4\n","batch_size = 1\n","PatchX = 128\n","PatchY = 128\n","PatchZ = 16\n","Kernel = 3\n","n_patches_per_image = 16\n","Rays = 128\n","startfilter = 48\n","use_gpu_opencl = True\n","GenerateNPZ = False\n","TrainUNET = False\n","TrainSTAR = False"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9I_dFcgGhPZi"},"source":["# Generate the npz file first and then train the model"]},{"cell_type":"code","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"Fl1YOvTjhPZj","executionInfo":{"status":"ok","timestamp":1621791451942,"user_tz":-120,"elapsed":13,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"7c5c28e1-2502-4407-a313-1d4ef476a51a"},"source":["\n","SmartSeeds3D(BaseDir = Data_dir, NPZfilename = NPZ_filename, model_name = Model_Name, model_dir = Model_dir, n_patches_per_image = n_patches_per_image,GenerateNPZ = GenerateNPZ, TrainUNET = TrainUNET, TrainSTAR = TrainSTAR, PatchX= PatchX, PatchY= PatchY, PatchZ = PatchZ,  use_gpu = use_gpu_opencl,  batch_size = batch_size, depth = NetworkDepth, kern_size = Kernel, startfilter = startfilter, n_rays = Rays, epochs = Epochs, learning_rate = LearningRate)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Instance segmentation masks: 24\n","Semantic segmentation masks: 24\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<vollseg.SmartSeeds3D.SmartSeeds3D at 0x7fa50b0d2f50>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rj10vic1hPZj","outputId":"96e49e15-e066-4186-fa36-c75e6d109b6f"},"source":["\n","TrainUNET = False\n","TrainSTAR = True\n","\n","SmartSeeds3D(BaseDir = Data_dir, NPZfilename = NPZ_filename, model_name = Model_Name, model_dir = Model_dir, n_patches_per_image = n_patches_per_image,GenerateNPZ = False, TrainUNET = TrainUNET, TrainSTAR = TrainSTAR, PatchX= PatchX, PatchY= PatchY, PatchZ = PatchZ,  use_gpu = use_gpu_opencl,  batch_size = batch_size, depth = NetworkDepth, kern_size = Kernel, startfilter = startfilter, n_rays = Rays, epochs = Epochs, learning_rate = LearningRate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Instance segmentation masks: 24\n","Semantic segmentation masks: 24\n","Training StarDistModel model with resnet backbone\n","24\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 24/24 [00:02<00:00, 10.44it/s]\n","100%|██████████| 24/24 [00:04<00:00,  4.90it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["number of images:  24\n","- training:        20\n","- validation:       4\n","Configuration for a :class:`StarDist3D` model.\n","\n","    Parameters\n","    ----------\n","    axes : str or None\n","        Axes of the input images.\n","    rays : Rays_Base, int, or None\n","        Ray factory (e.g. Ray_GoldenSpiral).\n","        If an integer then Ray_GoldenSpiral(rays) will be used\n","    n_channel_in : int\n","        Number of channels of given input image (default: 1).\n","    grid : (int,int,int)\n","        Subsampling factors (must be powers of 2) for each of the axes.\n","        Model will predict on a subsampled grid for increased efficiency and larger field of view.\n","    anisotropy : (float,float,float)\n","        Anisotropy of objects along each of the axes.\n","        Use ``None`` to disable only for (nearly) isotropic objects shapes.\n","        Also see ``utils.calculate_extents``.\n","    backbone : str\n","        Name of the neural network architecture to be used as backbone.\n","    kwargs : dict\n","        Overwrite (or add) configuration attributes (see below).\n","\n","\n","    Attributes\n","    ----------\n","    unet_n_depth : int\n","        Number of U-Net resolution levels (down/up-sampling layers).\n","    unet_kernel_size : (int,int,int)\n","        Convolution kernel size for all (U-Net) convolution layers.\n","    unet_n_filter_base : int\n","        Number of convolution kernels (feature channels) for first U-Net layer.\n","        Doubled after each down-sampling layer.\n","    unet_pool : (int,int,int)\n","        Maxpooling size for all (U-Net) convolution layers.\n","    net_conv_after_unet : int\n","        Number of filters of the extra convolution layer after U-Net (0 to disable).\n","    unet_* : *\n","        Additional parameters for U-net backbone.\n","    resnet_n_blocks : int\n","        Number of ResNet blocks.\n","    resnet_kernel_size : (int,int,int)\n","        Convolution kernel size for all ResNet blocks.\n","    resnet_n_filter_base : int\n","        Number of convolution kernels (feature channels) for ResNet blocks.\n","        (Number is doubled after every downsampling, see ``grid``.)\n","    net_conv_after_resnet : int\n","        Number of filters of the extra convolution layer after ResNet (0 to disable).\n","    resnet_* : *\n","        Additional parameters for ResNet backbone.\n","    train_patch_size : (int,int,int)\n","        Size of patches to be cropped from provided training images.\n","    train_background_reg : float\n","        Regularizer to encourage distance predictions on background regions to be 0.\n","    train_foreground_only : float\n","        Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.\n","    train_dist_loss : str\n","        Training loss for star-convex polygon distances ('mse' or 'mae').\n","    train_loss_weights : tuple of float\n","        Weights for losses relating to (probability, distance)\n","    train_epochs : int\n","        Number of training epochs.\n","    train_steps_per_epoch : int\n","        Number of parameter update steps per epoch.\n","    train_learning_rate : float\n","        Learning rate for training.\n","    train_batch_size : int\n","        Batch size for training.\n","    train_tensorboard : bool\n","        Enable TensorBoard for monitoring training progress.\n","    train_n_val_patches : int\n","        Number of patches to be extracted from validation images (``None`` = one patch per image).\n","    train_reduce_lr : dict\n","        Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.\n","    use_gpu : bool\n","        Indicate that the data generator should use OpenCL to do computations on the GPU.\n","\n","        .. _ReduceLROnPlateau: https://keras.io/callbacks/#reducelronplateau\n","    \n","Config3D(anisotropy=(1, 1, 1), axes='ZYXC', backbone='resnet', grid=(1, 1, 1), n_channel_in=1, n_channel_out=129, n_dim=3, n_rays=128, net_conv_after_resnet=128, net_input_shape=(None, None, None, 1), net_mask_shape=(None, None, None, 1), rays_json={'name': 'Rays_GoldenSpiral', 'kwargs': {'n': 128, 'anisotropy': (1, 1, 1)}}, resnet_activation='relu', resnet_batch_norm=False, resnet_kernel_init='he_normal', resnet_kernel_size=(3, 3, 3), resnet_n_blocks=3, resnet_n_conv_per_block=3, resnet_n_filter_base=48, train_background_reg=0.0001, train_batch_size=1, train_checkpoint='/content/drive/My Drive/data/VolumeSeg.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_dist_loss='mse', train_epochs=100, train_foreground_only=0.9, train_learning_rate=0.0001, train_loss_weights=(1, 0.2), train_n_val_patches=None, train_patch_size=(16, 128, 128), train_reduce_lr={'factor': 0.5, 'patience': 40, 'min_delta': 0}, train_steps_per_epoch=100, train_tensorboard=True, use_gpu=True)\n","Using default values: prob_thresh=0.5, nms_thresh=0.4.\n","(14, 14, 14) False\n","Error: Could not find scikit-tensor which is needed separable approximations...\n","pip install scikit-tensor-py3\n","Epoch 1/100\n","  6/100 [>.............................] - ETA: 52s - loss: 8.6180 - prob_loss: 0.7239 - dist_loss: 39.4705 - prob_kld: 0.7163 - dist_relevant_mae: 4.8824 - dist_relevant_mse: 39.4705WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1578s vs `on_train_batch_end` time: 0.3345s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow | Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1578s vs `on_train_batch_end` time: 0.3345s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["100/100 [==============================] - 60s 574ms/step - loss: 5.2893 - prob_loss: 0.3732 - dist_loss: 24.5801 - prob_kld: 0.3646 - dist_relevant_mae: 3.5719 - dist_relevant_mse: 24.5801 - val_loss: 2.4491 - val_prob_loss: 0.0371 - val_dist_loss: 12.0599 - val_prob_kld: 0.0281 - val_dist_relevant_mae: 2.4187 - val_dist_relevant_mse: 12.0598\n","Epoch 2/100\n","100/100 [==============================] - 56s 560ms/step - loss: 2.0284 - prob_loss: 0.0375 - dist_loss: 9.9548 - prob_kld: 0.0298 - dist_relevant_mae: 2.1047 - dist_relevant_mse: 9.9547 - val_loss: 1.9912 - val_prob_loss: 0.0428 - val_dist_loss: 9.7422 - val_prob_kld: 0.0341 - val_dist_relevant_mae: 2.1411 - val_dist_relevant_mse: 9.7421\n","Epoch 3/100\n","100/100 [==============================] - 56s 560ms/step - loss: 1.8451 - prob_loss: 0.0436 - dist_loss: 9.0078 - prob_kld: 0.0331 - dist_relevant_mae: 1.9860 - dist_relevant_mse: 9.0076 - val_loss: 2.0387 - val_prob_loss: 0.0242 - val_dist_loss: 10.0727 - val_prob_kld: 0.0155 - val_dist_relevant_mae: 2.2452 - val_dist_relevant_mse: 10.0725\n","Epoch 4/100\n","100/100 [==============================] - 56s 560ms/step - loss: 1.4771 - prob_loss: 0.0220 - dist_loss: 7.2755 - prob_kld: 0.0154 - dist_relevant_mae: 1.7545 - dist_relevant_mse: 7.2753 - val_loss: 2.0456 - val_prob_loss: 0.0746 - val_dist_loss: 9.8553 - val_prob_kld: 0.0659 - val_dist_relevant_mae: 2.0722 - val_dist_relevant_mse: 9.8552\n","Epoch 5/100\n","100/100 [==============================] - 56s 560ms/step - loss: 1.4784 - prob_loss: 0.0276 - dist_loss: 7.2537 - prob_kld: 0.0209 - dist_relevant_mae: 1.7883 - dist_relevant_mse: 7.2535 - val_loss: 1.4957 - val_prob_loss: 0.0166 - val_dist_loss: 7.3956 - val_prob_kld: 0.0079 - val_dist_relevant_mae: 1.7952 - val_dist_relevant_mse: 7.3953\n","Epoch 6/100\n","100/100 [==============================] - 56s 560ms/step - loss: 1.2677 - prob_loss: 0.0166 - dist_loss: 6.2557 - prob_kld: 0.0093 - dist_relevant_mae: 1.6392 - dist_relevant_mse: 6.2554 - val_loss: 1.2476 - val_prob_loss: 0.0185 - val_dist_loss: 6.1456 - val_prob_kld: 0.0098 - val_dist_relevant_mae: 1.6933 - val_dist_relevant_mse: 6.1453\n","Epoch 7/100\n","100/100 [==============================] - 56s 560ms/step - loss: 1.4409 - prob_loss: 0.0293 - dist_loss: 7.0583 - prob_kld: 0.0222 - dist_relevant_mae: 1.7414 - dist_relevant_mse: 7.0581 - val_loss: 1.2601 - val_prob_loss: 0.0164 - val_dist_loss: 6.2187 - val_prob_kld: 0.0078 - val_dist_relevant_mae: 1.6569 - val_dist_relevant_mse: 6.2184\n","Epoch 8/100\n","100/100 [==============================] - 56s 561ms/step - loss: 1.0943 - prob_loss: 0.0191 - dist_loss: 5.3758 - prob_kld: 0.0117 - dist_relevant_mae: 1.5175 - dist_relevant_mse: 5.3755 - val_loss: 1.2046 - val_prob_loss: 0.0160 - val_dist_loss: 5.9429 - val_prob_kld: 0.0074 - val_dist_relevant_mae: 1.6116 - val_dist_relevant_mse: 5.9427\n","Epoch 9/100\n","100/100 [==============================] - 56s 560ms/step - loss: 1.0044 - prob_loss: 0.0143 - dist_loss: 4.9508 - prob_kld: 0.0071 - dist_relevant_mae: 1.4410 - dist_relevant_mse: 4.9505 - val_loss: 1.1127 - val_prob_loss: 0.0165 - val_dist_loss: 5.4807 - val_prob_kld: 0.0079 - val_dist_relevant_mae: 1.5704 - val_dist_relevant_mse: 5.4804\n","Epoch 10/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.8733 - prob_loss: 0.0138 - dist_loss: 4.2978 - prob_kld: 0.0074 - dist_relevant_mae: 1.3234 - dist_relevant_mse: 4.2975 - val_loss: 1.2459 - val_prob_loss: 0.0205 - val_dist_loss: 6.1270 - val_prob_kld: 0.0119 - val_dist_relevant_mae: 1.6973 - val_dist_relevant_mse: 6.1267\n","Epoch 11/100\n","100/100 [==============================] - 56s 560ms/step - loss: 1.0026 - prob_loss: 0.0150 - dist_loss: 4.9381 - prob_kld: 0.0086 - dist_relevant_mae: 1.4118 - dist_relevant_mse: 4.9378 - val_loss: 1.1363 - val_prob_loss: 0.0146 - val_dist_loss: 5.6086 - val_prob_kld: 0.0059 - val_dist_relevant_mae: 1.5622 - val_dist_relevant_mse: 5.6084\n","Epoch 12/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.9497 - prob_loss: 0.0163 - dist_loss: 4.6671 - prob_kld: 0.0082 - dist_relevant_mae: 1.3952 - dist_relevant_mse: 4.6668 - val_loss: 0.9950 - val_prob_loss: 0.0160 - val_dist_loss: 4.8952 - val_prob_kld: 0.0073 - val_dist_relevant_mae: 1.4444 - val_dist_relevant_mse: 4.8951\n","Epoch 13/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.9254 - prob_loss: 0.0159 - dist_loss: 4.5479 - prob_kld: 0.0076 - dist_relevant_mae: 1.3234 - dist_relevant_mse: 4.5477 - val_loss: 1.6780 - val_prob_loss: 0.0199 - val_dist_loss: 8.2908 - val_prob_kld: 0.0112 - val_dist_relevant_mae: 1.9237 - val_dist_relevant_mse: 8.2907\n","Epoch 14/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.9185 - prob_loss: 0.0154 - dist_loss: 4.5155 - prob_kld: 0.0072 - dist_relevant_mae: 1.3677 - dist_relevant_mse: 4.5154 - val_loss: 0.9301 - val_prob_loss: 0.0152 - val_dist_loss: 4.5743 - val_prob_kld: 0.0066 - val_dist_relevant_mae: 1.3914 - val_dist_relevant_mse: 4.5741\n","Epoch 15/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.8616 - prob_loss: 0.0132 - dist_loss: 4.2420 - prob_kld: 0.0057 - dist_relevant_mae: 1.3358 - dist_relevant_mse: 4.2418 - val_loss: 0.9498 - val_prob_loss: 0.0150 - val_dist_loss: 4.6737 - val_prob_kld: 0.0064 - val_dist_relevant_mae: 1.4395 - val_dist_relevant_mse: 4.6735\n","Epoch 16/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.8119 - prob_loss: 0.0136 - dist_loss: 3.9912 - prob_kld: 0.0065 - dist_relevant_mae: 1.2808 - dist_relevant_mse: 3.9910 - val_loss: 0.8685 - val_prob_loss: 0.0143 - val_dist_loss: 4.2709 - val_prob_kld: 0.0057 - val_dist_relevant_mae: 1.3557 - val_dist_relevant_mse: 4.2707\n","Epoch 17/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.7695 - prob_loss: 0.0118 - dist_loss: 3.7882 - prob_kld: 0.0052 - dist_relevant_mae: 1.2082 - dist_relevant_mse: 3.7880 - val_loss: 0.8714 - val_prob_loss: 0.0152 - val_dist_loss: 4.2812 - val_prob_kld: 0.0065 - val_dist_relevant_mae: 1.3452 - val_dist_relevant_mse: 4.2810\n","Epoch 18/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.7278 - prob_loss: 0.0136 - dist_loss: 3.5710 - prob_kld: 0.0059 - dist_relevant_mae: 1.2362 - dist_relevant_mse: 3.5708 - val_loss: 0.7009 - val_prob_loss: 0.0146 - val_dist_loss: 3.4316 - val_prob_kld: 0.0059 - val_dist_relevant_mae: 1.1884 - val_dist_relevant_mse: 3.4314\n","Epoch 19/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.7215 - prob_loss: 0.0125 - dist_loss: 3.5449 - prob_kld: 0.0052 - dist_relevant_mae: 1.1709 - dist_relevant_mse: 3.5447 - val_loss: 0.8331 - val_prob_loss: 0.0149 - val_dist_loss: 4.0907 - val_prob_kld: 0.0063 - val_dist_relevant_mae: 1.3747 - val_dist_relevant_mse: 4.0905\n","Epoch 20/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.7013 - prob_loss: 0.0131 - dist_loss: 3.4408 - prob_kld: 0.0055 - dist_relevant_mae: 1.1897 - dist_relevant_mse: 3.4406 - val_loss: 0.7392 - val_prob_loss: 0.0145 - val_dist_loss: 3.6235 - val_prob_kld: 0.0058 - val_dist_relevant_mae: 1.1867 - val_dist_relevant_mse: 3.6233\n","Epoch 21/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.6373 - prob_loss: 0.0112 - dist_loss: 3.1302 - prob_kld: 0.0048 - dist_relevant_mae: 1.0758 - dist_relevant_mse: 3.1300 - val_loss: 0.7659 - val_prob_loss: 0.0148 - val_dist_loss: 3.7554 - val_prob_kld: 0.0062 - val_dist_relevant_mae: 1.2303 - val_dist_relevant_mse: 3.7552\n","Epoch 22/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.7646 - prob_loss: 0.0134 - dist_loss: 3.7558 - prob_kld: 0.0058 - dist_relevant_mae: 1.2080 - dist_relevant_mse: 3.7557 - val_loss: 0.7902 - val_prob_loss: 0.0146 - val_dist_loss: 3.8778 - val_prob_kld: 0.0060 - val_dist_relevant_mae: 1.3178 - val_dist_relevant_mse: 3.8776\n","Epoch 23/100\n","100/100 [==============================] - 56s 559ms/step - loss: 0.6262 - prob_loss: 0.0134 - dist_loss: 3.0636 - prob_kld: 0.0054 - dist_relevant_mae: 1.0966 - dist_relevant_mse: 3.0634 - val_loss: 0.6972 - val_prob_loss: 0.0148 - val_dist_loss: 3.4123 - val_prob_kld: 0.0061 - val_dist_relevant_mae: 1.1514 - val_dist_relevant_mse: 3.4121\n","Epoch 24/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.6322 - prob_loss: 0.0131 - dist_loss: 3.0958 - prob_kld: 0.0050 - dist_relevant_mae: 1.0728 - dist_relevant_mse: 3.0956 - val_loss: 0.6129 - val_prob_loss: 0.0139 - val_dist_loss: 2.9949 - val_prob_kld: 0.0053 - val_dist_relevant_mae: 1.0751 - val_dist_relevant_mse: 2.9947\n","Epoch 25/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.5397 - prob_loss: 0.0108 - dist_loss: 2.6449 - prob_kld: 0.0045 - dist_relevant_mae: 1.0129 - dist_relevant_mse: 2.6447 - val_loss: 0.6678 - val_prob_loss: 0.0144 - val_dist_loss: 3.2670 - val_prob_kld: 0.0058 - val_dist_relevant_mae: 1.1213 - val_dist_relevant_mse: 3.2669\n","Epoch 26/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.5709 - prob_loss: 0.0116 - dist_loss: 2.7968 - prob_kld: 0.0044 - dist_relevant_mae: 1.0437 - dist_relevant_mse: 2.7966 - val_loss: 0.5691 - val_prob_loss: 0.0141 - val_dist_loss: 2.7750 - val_prob_kld: 0.0054 - val_dist_relevant_mae: 1.0882 - val_dist_relevant_mse: 2.7748\n","Epoch 27/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.5304 - prob_loss: 0.0117 - dist_loss: 2.5935 - prob_kld: 0.0046 - dist_relevant_mae: 0.9935 - dist_relevant_mse: 2.5933 - val_loss: 0.5146 - val_prob_loss: 0.0146 - val_dist_loss: 2.5000 - val_prob_kld: 0.0060 - val_dist_relevant_mae: 1.0177 - val_dist_relevant_mse: 2.4998\n","Epoch 28/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.5053 - prob_loss: 0.0109 - dist_loss: 2.4719 - prob_kld: 0.0041 - dist_relevant_mae: 0.9874 - dist_relevant_mse: 2.4717 - val_loss: 0.5474 - val_prob_loss: 0.0138 - val_dist_loss: 2.6681 - val_prob_kld: 0.0052 - val_dist_relevant_mae: 1.0313 - val_dist_relevant_mse: 2.6679\n","Epoch 29/100\n","100/100 [==============================] - 56s 561ms/step - loss: 0.5184 - prob_loss: 0.0126 - dist_loss: 2.5293 - prob_kld: 0.0044 - dist_relevant_mae: 0.9911 - dist_relevant_mse: 2.5291 - val_loss: 0.7835 - val_prob_loss: 0.0140 - val_dist_loss: 3.8477 - val_prob_kld: 0.0054 - val_dist_relevant_mae: 1.2393 - val_dist_relevant_mse: 3.8475\n","Epoch 30/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.6803 - prob_loss: 0.0116 - dist_loss: 3.3434 - prob_kld: 0.0044 - dist_relevant_mae: 1.1352 - dist_relevant_mse: 3.3432 - val_loss: 0.5238 - val_prob_loss: 0.0136 - val_dist_loss: 2.5509 - val_prob_kld: 0.0049 - val_dist_relevant_mae: 1.0436 - val_dist_relevant_mse: 2.5507\n","Epoch 31/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4737 - prob_loss: 0.0109 - dist_loss: 2.3142 - prob_kld: 0.0041 - dist_relevant_mae: 0.9376 - dist_relevant_mse: 2.3140 - val_loss: 0.5522 - val_prob_loss: 0.0139 - val_dist_loss: 2.6917 - val_prob_kld: 0.0052 - val_dist_relevant_mae: 1.0134 - val_dist_relevant_mse: 2.6915\n","Epoch 32/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4725 - prob_loss: 0.0105 - dist_loss: 2.3100 - prob_kld: 0.0038 - dist_relevant_mae: 0.9278 - dist_relevant_mse: 2.3098 - val_loss: 0.5869 - val_prob_loss: 0.0138 - val_dist_loss: 2.8652 - val_prob_kld: 0.0052 - val_dist_relevant_mae: 1.0705 - val_dist_relevant_mse: 2.8650\n","Epoch 33/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.5032 - prob_loss: 0.0106 - dist_loss: 2.4629 - prob_kld: 0.0037 - dist_relevant_mae: 0.9661 - dist_relevant_mse: 2.4627 - val_loss: 0.6322 - val_prob_loss: 0.0140 - val_dist_loss: 3.0911 - val_prob_kld: 0.0053 - val_dist_relevant_mae: 1.1032 - val_dist_relevant_mse: 3.0909\n","Epoch 34/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.5075 - prob_loss: 0.0112 - dist_loss: 2.4817 - prob_kld: 0.0043 - dist_relevant_mae: 0.9852 - dist_relevant_mse: 2.4816 - val_loss: 0.5194 - val_prob_loss: 0.0135 - val_dist_loss: 2.5293 - val_prob_kld: 0.0049 - val_dist_relevant_mae: 0.9769 - val_dist_relevant_mse: 2.5291\n","Epoch 35/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.5125 - prob_loss: 0.0108 - dist_loss: 2.5086 - prob_kld: 0.0036 - dist_relevant_mae: 0.9690 - dist_relevant_mse: 2.5084 - val_loss: 0.5023 - val_prob_loss: 0.0142 - val_dist_loss: 2.4409 - val_prob_kld: 0.0055 - val_dist_relevant_mae: 1.0008 - val_dist_relevant_mse: 2.4407\n","Epoch 36/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4449 - prob_loss: 0.0107 - dist_loss: 2.1709 - prob_kld: 0.0036 - dist_relevant_mae: 0.9241 - dist_relevant_mse: 2.1707 - val_loss: 0.5492 - val_prob_loss: 0.0136 - val_dist_loss: 2.6782 - val_prob_kld: 0.0050 - val_dist_relevant_mae: 1.0804 - val_dist_relevant_mse: 2.6780\n","Epoch 37/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4733 - prob_loss: 0.0087 - dist_loss: 2.3226 - prob_kld: 0.0031 - dist_relevant_mae: 0.9506 - dist_relevant_mse: 2.3224 - val_loss: 0.4678 - val_prob_loss: 0.0132 - val_dist_loss: 2.2731 - val_prob_kld: 0.0046 - val_dist_relevant_mae: 0.9486 - val_dist_relevant_mse: 2.2729\n","Epoch 38/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4454 - prob_loss: 0.0121 - dist_loss: 2.1664 - prob_kld: 0.0039 - dist_relevant_mae: 0.9029 - dist_relevant_mse: 2.1662 - val_loss: 0.5672 - val_prob_loss: 0.0137 - val_dist_loss: 2.7679 - val_prob_kld: 0.0050 - val_dist_relevant_mae: 1.0411 - val_dist_relevant_mse: 2.7677\n","Epoch 39/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4867 - prob_loss: 0.0122 - dist_loss: 2.3726 - prob_kld: 0.0041 - dist_relevant_mae: 0.9505 - dist_relevant_mse: 2.3724 - val_loss: 0.5063 - val_prob_loss: 0.0133 - val_dist_loss: 2.4648 - val_prob_kld: 0.0047 - val_dist_relevant_mae: 0.9689 - val_dist_relevant_mse: 2.4647\n","Epoch 40/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.3690 - prob_loss: 0.0081 - dist_loss: 1.8048 - prob_kld: 0.0031 - dist_relevant_mae: 0.8390 - dist_relevant_mse: 1.8046 - val_loss: 0.5136 - val_prob_loss: 0.0131 - val_dist_loss: 2.5022 - val_prob_kld: 0.0045 - val_dist_relevant_mae: 0.9787 - val_dist_relevant_mse: 2.5020\n","Epoch 41/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4807 - prob_loss: 0.0127 - dist_loss: 2.3401 - prob_kld: 0.0042 - dist_relevant_mae: 0.9143 - dist_relevant_mse: 2.3399 - val_loss: 0.5033 - val_prob_loss: 0.0133 - val_dist_loss: 2.4498 - val_prob_kld: 0.0047 - val_dist_relevant_mae: 1.0133 - val_dist_relevant_mse: 2.4496\n","Epoch 42/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4313 - prob_loss: 0.0121 - dist_loss: 2.0960 - prob_kld: 0.0042 - dist_relevant_mae: 0.9045 - dist_relevant_mse: 2.0958 - val_loss: 0.4572 - val_prob_loss: 0.0130 - val_dist_loss: 2.2209 - val_prob_kld: 0.0044 - val_dist_relevant_mae: 0.9458 - val_dist_relevant_mse: 2.2207\n","Epoch 43/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.3823 - prob_loss: 0.0094 - dist_loss: 1.8642 - prob_kld: 0.0033 - dist_relevant_mae: 0.8512 - dist_relevant_mse: 1.8640 - val_loss: 0.4618 - val_prob_loss: 0.0129 - val_dist_loss: 2.2441 - val_prob_kld: 0.0043 - val_dist_relevant_mae: 0.9381 - val_dist_relevant_mse: 2.2439\n","Epoch 44/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4068 - prob_loss: 0.0099 - dist_loss: 1.9847 - prob_kld: 0.0034 - dist_relevant_mae: 0.8696 - dist_relevant_mse: 1.9845 - val_loss: 0.4441 - val_prob_loss: 0.0130 - val_dist_loss: 2.1556 - val_prob_kld: 0.0044 - val_dist_relevant_mae: 0.9450 - val_dist_relevant_mse: 2.1554\n","Epoch 45/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4017 - prob_loss: 0.0103 - dist_loss: 1.9572 - prob_kld: 0.0034 - dist_relevant_mae: 0.8595 - dist_relevant_mse: 1.9570 - val_loss: 0.4352 - val_prob_loss: 0.0132 - val_dist_loss: 2.1101 - val_prob_kld: 0.0046 - val_dist_relevant_mae: 0.9197 - val_dist_relevant_mse: 2.1099\n","Epoch 46/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4123 - prob_loss: 0.0101 - dist_loss: 2.0110 - prob_kld: 0.0035 - dist_relevant_mae: 0.8563 - dist_relevant_mse: 2.0108 - val_loss: 0.4411 - val_prob_loss: 0.0131 - val_dist_loss: 2.1398 - val_prob_kld: 0.0045 - val_dist_relevant_mae: 0.9046 - val_dist_relevant_mse: 2.1396\n","Epoch 47/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4056 - prob_loss: 0.0111 - dist_loss: 1.9724 - prob_kld: 0.0038 - dist_relevant_mae: 0.8337 - dist_relevant_mse: 1.9723 - val_loss: 0.4767 - val_prob_loss: 0.0130 - val_dist_loss: 2.3182 - val_prob_kld: 0.0044 - val_dist_relevant_mae: 0.9887 - val_dist_relevant_mse: 2.3180\n","Epoch 48/100\n","100/100 [==============================] - 56s 560ms/step - loss: 0.4669 - prob_loss: 0.0105 - dist_loss: 2.2821 - prob_kld: 0.0034 - dist_relevant_mae: 0.9176 - dist_relevant_mse: 2.2819 - val_loss: 0.5007 - val_prob_loss: 0.0132 - val_dist_loss: 2.4376 - val_prob_kld: 0.0045 - val_dist_relevant_mae: 0.9965 - val_dist_relevant_mse: 2.4375\n","Epoch 49/100\n"," 12/100 [==>...........................] - ETA: 48s - loss: 0.4081 - prob_loss: 0.0095 - dist_loss: 1.9933 - prob_kld: 0.0029 - dist_relevant_mae: 0.8587 - dist_relevant_mse: 1.9931"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IRT1VPzqhPZj"},"source":[""],"execution_count":null,"outputs":[]}]}
=======
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"ColabTrainModel.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8WrUuZChPZe","executionInfo":{"status":"ok","timestamp":1621779986935,"user_tz":-120,"elapsed":20064,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"7d1ffb15-f719-4bff-9fda-13a5212b62e2"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuWFMg8-hPZg","executionInfo":{"status":"ok","timestamp":1621780006362,"user_tz":-120,"elapsed":19431,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"25e1d9d6-ebb3-4c87-83b9-d17b9e7b0a82"},"source":["!pip install tiffile\n","\n","\n","!pip install gputools\n","\n","!pip install imagecodecs\n","!pip install vollseg\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tiffile\n","  Downloading https://files.pythonhosted.org/packages/86/d7/d8fdfc8da77fde224e7f21d0c6612614852242b9631e31ca3366edb0d3f2/tiffile-2018.10.18-py2.py3-none-any.whl\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from tiffile) (2021.4.8)\n","Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from tifffile->tiffile) (1.19.5)\n","Installing collected packages: tiffile\n","Successfully installed tiffile-2018.10.18\n","Collecting gputools\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/4a/26f33fb48305bd05bcccdf02121d0ec05c895dc496f250171d682ef9b3bf/gputools-0.2.10-py3-none-any.whl (150kB)\n","\u001b[K     |████████████████████████████████| 153kB 2.9MB/s \n","\u001b[?25hCollecting configparser; python_version >= \"3.0\"\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from gputools) (1.19.5)\n","Collecting reikna>=0.6.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/05/e8643dd1efc302291692286fc4fc8cefe277eb7de8a3d95a0e48e7dba2ef/reikna-0.7.5.tar.gz (189kB)\n","\u001b[K     |████████████████████████████████| 194kB 13.8MB/s \n","\u001b[?25hCollecting pyopencl>=2016.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/f3/dff518aac1a06c9f1a2e9f95c6914524162f1f70652649596861e85fafb3/pyopencl-2021.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (879kB)\n","\u001b[K     |████████████████████████████████| 880kB 34.9MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gputools) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gputools) (1.15.0)\n","Collecting mako>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n","\u001b[?25hCollecting funcsigs>=0.3\n","  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n","Collecting pytools>=2017.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/5b/136e5688da9bbd915ee8190bfd6a007fc0b19d71f26d5a2ab4b737b2eeb4/pytools-2021.2.6.tar.gz (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n","\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyopencl>=2016.1->gputools) (1.4.4)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako>=0.8.0->reikna>=0.6.7->gputools) (2.0.0)\n","Building wheels for collected packages: reikna, pytools\n","  Building wheel for reikna (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for reikna: filename=reikna-0.7.5-cp37-none-any.whl size=122266 sha256=cbdf9825d64373755d59308385e837f95b165fd619fb3dd1321d3b2ead25f68e\n","  Stored in directory: /root/.cache/pip/wheels/82/2d/ba/12c9ba3637183463c471bcf352f5bc1703ab7dfbec9842f04a\n","  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytools: filename=pytools-2021.2.6-py2.py3-none-any.whl size=60643 sha256=1b6900a79b513100195adf31ae727d1e8792656c19177ef54e571f5bb86ae1bf\n","  Stored in directory: /root/.cache/pip/wheels/8c/a6/65/447b9b4fd1d9bde84ad2fea2431a38f69f3fb573476a98ae03\n","Successfully built reikna pytools\n","Installing collected packages: configparser, mako, funcsigs, reikna, pytools, pyopencl, gputools\n","Successfully installed configparser-5.0.2 funcsigs-1.0.2 gputools-0.2.10 mako-1.1.4 pyopencl-2021.2.2 pytools-2021.2.6 reikna-0.7.5\n","Collecting imagecodecs\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/b7/08b829a7a90ca08733faeb414169b508151d436dde264a7b9ed5e2865d8a/imagecodecs-2021.5.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.0MB)\n","\u001b[K     |████████████████████████████████| 30.0MB 172kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.19.5)\n","Installing collected packages: imagecodecs\n","Successfully installed imagecodecs-2021.5.20\n","Collecting vollseg\n","  Downloading https://files.pythonhosted.org/packages/5e/91/cc4d7973ec2021d845e238a93299222d71c2623471189904f19d021b9443/vollseg-1.0.1-py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from vollseg) (3.2.2)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from vollseg) (2021.4.8)\n","Collecting csbdeep\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/4b/f0c9c85114c7660309903ec987128d31c6aef8e3d3ab35a8d30d1c947d5d/csbdeep-0.6.1-py2.py3-none-any.whl (68kB)\n","\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.1.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from vollseg) (0.16.2)\n","Collecting stardist\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/48/c5c3dd65a177751945eb6d730ac63c7f9bd2811cc2cba5369cac42c07be0/stardist-0.6.2-cp37-cp37m-manylinux2014_x86_64.whl (2.4MB)\n","\u001b[K     |████████████████████████████████| 2.4MB 10.2MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (2.8.1)\n","Collecting keras<2.4,>=2.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n","\u001b[K     |████████████████████████████████| 378kB 35.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (4.41.1)\n","Requirement already satisfied: h5py<3 in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->vollseg) (2018.9)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (7.1.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (1.1.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (2.5.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from stardist->vollseg) (0.51.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep->vollseg) (1.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep->vollseg) (3.13)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->vollseg) (4.4.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->stardist->vollseg) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->stardist->vollseg) (56.1.0)\n","Installing collected packages: keras-applications, keras, csbdeep, stardist, vollseg\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed csbdeep-0.6.1 keras-2.3.1 keras-applications-1.0.8 stardist-0.6.2 vollseg-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNKAD9UkhPZh","executionInfo":{"status":"ok","timestamp":1621780013319,"user_tz":-120,"elapsed":6975,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"5f3e9b5d-f991-4d64-b30b-f02bc1336d36"},"source":["%cd '/content/drive/My Drive/VollSeg/'\n","import os\n","import glob\n","import sys\n","import numpy as np\n","from tqdm import tqdm\n","from tifffile import imread, imwrite\n","from pathlib import Path\n","from vollseg import SmartSeeds3D\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/VollSeg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z5yD4cofhPZh"},"source":["# In the cell below specify the following:\n","\n","1) Directory where the training data is, inside this directory there should be the two subfolders called Raw and Mask. Inside the Raw folder are the raw images and inside the Mask folder are the labelled images.\n","\n","2) The training data for doing UNET training is stored in NPZ format so please specify the NPZ filename which is suitable for your data.\n","\n","3) Model directory is where the trained Neural network models are stored, please chooose a location if you want to change the default location which is where the training data is.\n","\n","4) Copy Model name is optional, in case you have a previouis trained model and want to re-train it on new data but store it with a new name.\n","\n","5) Model name is the unique name of the trained models."]},{"cell_type":"code","metadata":{"id":"Vri8MgwShPZh","executionInfo":{"status":"ok","timestamp":1621780013321,"user_tz":-120,"elapsed":14,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":["Data_dir = '/content/drive/My Drive/data/'\n","NPZ_filename = 'VolumeSeg'\n","Model_dir = '/content/drive/My Drive/data/'\n","Model_Name = 'VolumeSeg'"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqnKEJlUhPZi"},"source":["# In this cell choose the network training parameters for the Neural Network\n","\n","1) NetworkDepth = Depth of the network, with each increasing depth the image is downsampled by 2 hence the XYZ dimension of the data / 2^depth has to be greater than 1.\n","\n","2) Epochs, training for longer epochs ensures a well converged network and requires longer GPU runtimes.\n","\n","3) Learning rate is the parameter which controls the step size used in the optimization process and it should not be greater than 0.001 at the start of the training.\n","\n","4) batch size controls the number of images used for doing stochastic gradient descent and is a parameter that is limited by the GPU RAM available, if you do not have a lot of ran batch size < 10 should be optimal. \n","\n","5) PatchX,Y,Z is the patch size used for making patches out of the iamge data. The original image is broken down into patches for training. Patch size is chosen based on having enough context for the network to learn but at the same time not being too big to obscure memory usage.\n","\n","6) Kernel is the receptive field of the neural network, usual choices are 3,5 or 7 but not larger than that. This is the size of the convolutional kernel used in the network\n","\n","7) n_patches_per_image is the number of patches sampled for each image to create the npz file, choose an optimal value so that the file is not too big for the computer memory. \n","\n","8) Rays is the number of rays used the learn the distance map, low rays decreases the spatial resoultion and high rays are able to resolve the shape better.\n","\n","\n","9) OpenCL is a boolean parameter that is set true if you want to do some opencl computations on the GPU, this requires GPU tools but if you do not have them set this to false.\n","\n","Some optimal values have been chosen by default and should work well for any NVDIA enabled GPU computer"]},{"cell_type":"code","metadata":{"id":"Sh-WQOu7hPZi","executionInfo":{"status":"ok","timestamp":1621780013322,"user_tz":-120,"elapsed":14,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":["#Network training parameters\n","NetworkDepth = 3\n","Epochs = 100\n","LearningRate = 1.0E-4\n","batch_size = 1\n","PatchX = 128\n","PatchY = 128\n","PatchZ = 16\n","Kernel = 3\n","n_patches_per_image = 16\n","Rays = 128\n","startfilter = 48\n","use_gpu_opencl = True\n","GenerateNPZ = True\n","TrainUNET = False\n","TrainSTAR = False"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9I_dFcgGhPZi"},"source":["# Generate the npz file first and then train the model"]},{"cell_type":"code","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"Fl1YOvTjhPZj","executionInfo":{"status":"ok","timestamp":1621780093816,"user_tz":-120,"elapsed":80507,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"34dca268-9b83-49f7-d202-fc215210333a"},"source":["\n","SmartSeeds3D(BaseDir = Data_dir, NPZfilename = NPZ_filename, model_name = Model_Name, model_dir = Model_dir, n_patches_per_image = n_patches_per_image,GenerateNPZ = GenerateNPZ, TrainUNET = TrainUNET, TrainSTAR = TrainSTAR, PatchX= PatchX, PatchY= PatchY, PatchZ = PatchZ,  use_gpu = use_gpu_opencl,  batch_size = batch_size, depth = NetworkDepth, kern_size = Kernel, startfilter = startfilter, n_rays = Rays, epochs = Epochs, learning_rate = LearningRate)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Instance segmentation masks: 24\n","Semantic segmentation masks: 24\n","==================================================================\n","   24 raw images x    1 transformations   =    24 images\n","   24 images     x   16 patches per image =   384 patches in total\n","==================================================================\n","Input data:\n","/content/drive/My Drive/data/: target='BinaryMask/', sources=['Raw/'], axes='ZYX', pattern='*.tif*'\n","==================================================================\n","Transformations:\n","1 x Identity\n","==================================================================\n","Patch size:\n","16 x 128 x 128\n","==================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 24/24 [01:11<00:00,  2.96s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Saving data to /content/drive/My Drive/data/VolumeSeg.npz.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<vollseg.SmartSeeds3D.SmartSeeds3D at 0x7f4bafe59d90>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rj10vic1hPZj","outputId":"e8f2d926-3c10-4482-bd29-9229752318f7"},"source":["\n","TrainUNET = True\n","TrainSTAR = True\n","\n","SmartSeeds3D(BaseDir = Data_dir, NPZfilename = NPZ_filename, model_name = Model_Name, model_dir = Model_dir, n_patches_per_image = n_patches_per_image,GenerateNPZ = False, TrainUNET = TrainUNET, TrainSTAR = TrainSTAR, PatchX= PatchX, PatchY= PatchY, PatchZ = PatchZ,  use_gpu = use_gpu_opencl,  batch_size = batch_size, depth = NetworkDepth, kern_size = Kernel, startfilter = startfilter, n_rays = Rays, epochs = Epochs, learning_rate = LearningRate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Instance segmentation masks: 24\n","Semantic segmentation masks: 24\n","==================================================================\n","   24 raw images x    1 transformations   =    24 images\n","   24 images     x   16 patches per image =   384 patches in total\n","==================================================================\n","Input data:\n","/content/drive/My Drive/data/: target='BinaryMask/', sources=['Raw/'], axes='ZYX', pattern='*.tif*'\n","==================================================================\n","Transformations:\n","1 x Identity\n","==================================================================\n","Patch size:\n","16 x 128 x 128\n","==================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 24/24 [00:14<00:00,  1.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Saving data to /content/drive/My Drive/data/VolumeSeg.npz.\n","Training UNET model\n","number of training images:\t 346\n","number of validation images:\t 38\n","image size (3D):\t\t (16, 128, 128)\n","axes:\t\t\t\t SZYXC\n","channels in / out:\t\t 1 / 1\n","Config(axes='ZYXC', n_channel_in=1, n_channel_out=1, n_dim=3, probabilistic=False, train_batch_size=1, train_checkpoint='weights_best.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_epochs=100, train_learning_rate=0.0001, train_loss='mse', train_reduce_lr={'patience': 5, 'factor': 0.5}, train_steps_per_epoch=400, train_tensorboard=True, unet_input_shape=(None, None, None, 1), unet_kern_size=3, unet_last_activation='linear', unet_n_depth=3, unet_n_first=48, unet_residual=True)\n"],"name":"stdout"},{"output_type":"stream","text":["base_model.py (148): output path for model already exists, files may be overwritten: /content/drive/My Drive/data/UNETVolumeSeg\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","  6/400 [..............................] - ETA: 1:44 - loss: 0.0234 - mse: 0.0234 - mae: 0.0525WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0743s vs `on_train_batch_end` time: 0.1590s). Check your callbacks.\n","179/400 [============>.................] - ETA: 58s - loss: 0.0180 - mse: 0.0180 - mae: 0.0525"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IRT1VPzqhPZj","executionInfo":{"status":"aborted","timestamp":1621780093816,"user_tz":-120,"elapsed":8,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":[""],"execution_count":null,"outputs":[]}]}
>>>>>>> c936a43db86e827802dd3b428751308ae75df689
