{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"ColabTrainModel.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8WrUuZChPZe","executionInfo":{"status":"ok","timestamp":1621779986935,"user_tz":-120,"elapsed":20064,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"7d1ffb15-f719-4bff-9fda-13a5212b62e2"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuWFMg8-hPZg","executionInfo":{"status":"ok","timestamp":1621780006362,"user_tz":-120,"elapsed":19431,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"25e1d9d6-ebb3-4c87-83b9-d17b9e7b0a82"},"source":["!pip install tiffile\n","\n","\n","!pip install gputools\n","\n","!pip install imagecodecs\n","!pip install vollseg\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tiffile\n","  Downloading https://files.pythonhosted.org/packages/86/d7/d8fdfc8da77fde224e7f21d0c6612614852242b9631e31ca3366edb0d3f2/tiffile-2018.10.18-py2.py3-none-any.whl\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from tiffile) (2021.4.8)\n","Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from tifffile->tiffile) (1.19.5)\n","Installing collected packages: tiffile\n","Successfully installed tiffile-2018.10.18\n","Collecting gputools\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/4a/26f33fb48305bd05bcccdf02121d0ec05c895dc496f250171d682ef9b3bf/gputools-0.2.10-py3-none-any.whl (150kB)\n","\u001b[K     |████████████████████████████████| 153kB 2.9MB/s \n","\u001b[?25hCollecting configparser; python_version >= \"3.0\"\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from gputools) (1.19.5)\n","Collecting reikna>=0.6.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/05/e8643dd1efc302291692286fc4fc8cefe277eb7de8a3d95a0e48e7dba2ef/reikna-0.7.5.tar.gz (189kB)\n","\u001b[K     |████████████████████████████████| 194kB 13.8MB/s \n","\u001b[?25hCollecting pyopencl>=2016.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/f3/dff518aac1a06c9f1a2e9f95c6914524162f1f70652649596861e85fafb3/pyopencl-2021.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (879kB)\n","\u001b[K     |████████████████████████████████| 880kB 34.9MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gputools) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gputools) (1.15.0)\n","Collecting mako>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n","\u001b[?25hCollecting funcsigs>=0.3\n","  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n","Collecting pytools>=2017.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/5b/136e5688da9bbd915ee8190bfd6a007fc0b19d71f26d5a2ab4b737b2eeb4/pytools-2021.2.6.tar.gz (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n","\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyopencl>=2016.1->gputools) (1.4.4)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako>=0.8.0->reikna>=0.6.7->gputools) (2.0.0)\n","Building wheels for collected packages: reikna, pytools\n","  Building wheel for reikna (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for reikna: filename=reikna-0.7.5-cp37-none-any.whl size=122266 sha256=cbdf9825d64373755d59308385e837f95b165fd619fb3dd1321d3b2ead25f68e\n","  Stored in directory: /root/.cache/pip/wheels/82/2d/ba/12c9ba3637183463c471bcf352f5bc1703ab7dfbec9842f04a\n","  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytools: filename=pytools-2021.2.6-py2.py3-none-any.whl size=60643 sha256=1b6900a79b513100195adf31ae727d1e8792656c19177ef54e571f5bb86ae1bf\n","  Stored in directory: /root/.cache/pip/wheels/8c/a6/65/447b9b4fd1d9bde84ad2fea2431a38f69f3fb573476a98ae03\n","Successfully built reikna pytools\n","Installing collected packages: configparser, mako, funcsigs, reikna, pytools, pyopencl, gputools\n","Successfully installed configparser-5.0.2 funcsigs-1.0.2 gputools-0.2.10 mako-1.1.4 pyopencl-2021.2.2 pytools-2021.2.6 reikna-0.7.5\n","Collecting imagecodecs\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/b7/08b829a7a90ca08733faeb414169b508151d436dde264a7b9ed5e2865d8a/imagecodecs-2021.5.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.0MB)\n","\u001b[K     |████████████████████████████████| 30.0MB 172kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.19.5)\n","Installing collected packages: imagecodecs\n","Successfully installed imagecodecs-2021.5.20\n","Collecting vollseg\n","  Downloading https://files.pythonhosted.org/packages/5e/91/cc4d7973ec2021d845e238a93299222d71c2623471189904f19d021b9443/vollseg-1.0.1-py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from vollseg) (3.2.2)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from vollseg) (2021.4.8)\n","Collecting csbdeep\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/4b/f0c9c85114c7660309903ec987128d31c6aef8e3d3ab35a8d30d1c947d5d/csbdeep-0.6.1-py2.py3-none-any.whl (68kB)\n","\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from vollseg) (1.1.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from vollseg) (0.16.2)\n","Collecting stardist\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/48/c5c3dd65a177751945eb6d730ac63c7f9bd2811cc2cba5369cac42c07be0/stardist-0.6.2-cp37-cp37m-manylinux2014_x86_64.whl (2.4MB)\n","\u001b[K     |████████████████████████████████| 2.4MB 10.2MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->vollseg) (2.8.1)\n","Collecting keras<2.4,>=2.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n","\u001b[K     |████████████████████████████████| 378kB 35.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (4.41.1)\n","Requirement already satisfied: h5py<3 in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from csbdeep->vollseg) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->vollseg) (2018.9)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (7.1.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (1.1.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->vollseg) (2.5.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from stardist->vollseg) (0.51.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep->vollseg) (1.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras<2.4,>=2.1.2->csbdeep->vollseg) (3.13)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->vollseg) (4.4.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->stardist->vollseg) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->stardist->vollseg) (56.1.0)\n","Installing collected packages: keras-applications, keras, csbdeep, stardist, vollseg\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed csbdeep-0.6.1 keras-2.3.1 keras-applications-1.0.8 stardist-0.6.2 vollseg-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNKAD9UkhPZh","executionInfo":{"status":"ok","timestamp":1621780013319,"user_tz":-120,"elapsed":6975,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"5f3e9b5d-f991-4d64-b30b-f02bc1336d36"},"source":["%cd '/content/drive/My Drive/VollSeg/'\n","import os\n","import glob\n","import sys\n","import numpy as np\n","from tqdm import tqdm\n","from tifffile import imread, imwrite\n","from pathlib import Path\n","from vollseg import SmartSeeds3D\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/VollSeg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z5yD4cofhPZh"},"source":["# In the cell below specify the following:\n","\n","1) Directory where the training data is, inside this directory there should be the two subfolders called Raw and Mask. Inside the Raw folder are the raw images and inside the Mask folder are the labelled images.\n","\n","2) The training data for doing UNET training is stored in NPZ format so please specify the NPZ filename which is suitable for your data.\n","\n","3) Model directory is where the trained Neural network models are stored, please chooose a location if you want to change the default location which is where the training data is.\n","\n","4) Copy Model name is optional, in case you have a previouis trained model and want to re-train it on new data but store it with a new name.\n","\n","5) Model name is the unique name of the trained models."]},{"cell_type":"code","metadata":{"id":"Vri8MgwShPZh","executionInfo":{"status":"ok","timestamp":1621780013321,"user_tz":-120,"elapsed":14,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":["Data_dir = '/content/drive/My Drive/data/'\n","NPZ_filename = 'VolumeSeg'\n","Model_dir = '/content/drive/My Drive/data/'\n","Model_Name = 'VolumeSeg'"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqnKEJlUhPZi"},"source":["# In this cell choose the network training parameters for the Neural Network\n","\n","1) NetworkDepth = Depth of the network, with each increasing depth the image is downsampled by 2 hence the XYZ dimension of the data / 2^depth has to be greater than 1.\n","\n","2) Epochs, training for longer epochs ensures a well converged network and requires longer GPU runtimes.\n","\n","3) Learning rate is the parameter which controls the step size used in the optimization process and it should not be greater than 0.001 at the start of the training.\n","\n","4) batch size controls the number of images used for doing stochastic gradient descent and is a parameter that is limited by the GPU RAM available, if you do not have a lot of ran batch size < 10 should be optimal. \n","\n","5) PatchX,Y,Z is the patch size used for making patches out of the iamge data. The original image is broken down into patches for training. Patch size is chosen based on having enough context for the network to learn but at the same time not being too big to obscure memory usage.\n","\n","6) Kernel is the receptive field of the neural network, usual choices are 3,5 or 7 but not larger than that. This is the size of the convolutional kernel used in the network\n","\n","7) n_patches_per_image is the number of patches sampled for each image to create the npz file, choose an optimal value so that the file is not too big for the computer memory. \n","\n","8) Rays is the number of rays used the learn the distance map, low rays decreases the spatial resoultion and high rays are able to resolve the shape better.\n","\n","\n","9) OpenCL is a boolean parameter that is set true if you want to do some opencl computations on the GPU, this requires GPU tools but if you do not have them set this to false.\n","\n","Some optimal values have been chosen by default and should work well for any NVDIA enabled GPU computer"]},{"cell_type":"code","metadata":{"id":"Sh-WQOu7hPZi","executionInfo":{"status":"ok","timestamp":1621780013322,"user_tz":-120,"elapsed":14,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":["#Network training parameters\n","NetworkDepth = 3\n","Epochs = 100\n","LearningRate = 1.0E-4\n","batch_size = 1\n","PatchX = 128\n","PatchY = 128\n","PatchZ = 16\n","Kernel = 3\n","n_patches_per_image = 16\n","Rays = 128\n","startfilter = 48\n","use_gpu_opencl = True\n","GenerateNPZ = True\n","TrainUNET = False\n","TrainSTAR = False"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9I_dFcgGhPZi"},"source":["# Generate the npz file first and then train the model"]},{"cell_type":"code","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"Fl1YOvTjhPZj","executionInfo":{"status":"ok","timestamp":1621780093816,"user_tz":-120,"elapsed":80507,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}},"outputId":"34dca268-9b83-49f7-d202-fc215210333a"},"source":["\n","SmartSeeds3D(BaseDir = Data_dir, NPZfilename = NPZ_filename, model_name = Model_Name, model_dir = Model_dir, n_patches_per_image = n_patches_per_image,GenerateNPZ = GenerateNPZ, TrainUNET = TrainUNET, TrainSTAR = TrainSTAR, PatchX= PatchX, PatchY= PatchY, PatchZ = PatchZ,  use_gpu = use_gpu_opencl,  batch_size = batch_size, depth = NetworkDepth, kern_size = Kernel, startfilter = startfilter, n_rays = Rays, epochs = Epochs, learning_rate = LearningRate)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Instance segmentation masks: 24\n","Semantic segmentation masks: 24\n","==================================================================\n","   24 raw images x    1 transformations   =    24 images\n","   24 images     x   16 patches per image =   384 patches in total\n","==================================================================\n","Input data:\n","/content/drive/My Drive/data/: target='BinaryMask/', sources=['Raw/'], axes='ZYX', pattern='*.tif*'\n","==================================================================\n","Transformations:\n","1 x Identity\n","==================================================================\n","Patch size:\n","16 x 128 x 128\n","==================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 24/24 [01:11<00:00,  2.96s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Saving data to /content/drive/My Drive/data/VolumeSeg.npz.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<vollseg.SmartSeeds3D.SmartSeeds3D at 0x7f4bafe59d90>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rj10vic1hPZj","outputId":"e8f2d926-3c10-4482-bd29-9229752318f7"},"source":["\n","TrainUNET = True\n","TrainSTAR = True\n","\n","SmartSeeds3D(BaseDir = Data_dir, NPZfilename = NPZ_filename, model_name = Model_Name, model_dir = Model_dir, n_patches_per_image = n_patches_per_image,GenerateNPZ = False, TrainUNET = TrainUNET, TrainSTAR = TrainSTAR, PatchX= PatchX, PatchY= PatchY, PatchZ = PatchZ,  use_gpu = use_gpu_opencl,  batch_size = batch_size, depth = NetworkDepth, kern_size = Kernel, startfilter = startfilter, n_rays = Rays, epochs = Epochs, learning_rate = LearningRate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Instance segmentation masks: 24\n","Semantic segmentation masks: 24\n","==================================================================\n","   24 raw images x    1 transformations   =    24 images\n","   24 images     x   16 patches per image =   384 patches in total\n","==================================================================\n","Input data:\n","/content/drive/My Drive/data/: target='BinaryMask/', sources=['Raw/'], axes='ZYX', pattern='*.tif*'\n","==================================================================\n","Transformations:\n","1 x Identity\n","==================================================================\n","Patch size:\n","16 x 128 x 128\n","==================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 24/24 [00:14<00:00,  1.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Saving data to /content/drive/My Drive/data/VolumeSeg.npz.\n","Training UNET model\n","number of training images:\t 346\n","number of validation images:\t 38\n","image size (3D):\t\t (16, 128, 128)\n","axes:\t\t\t\t SZYXC\n","channels in / out:\t\t 1 / 1\n","Config(axes='ZYXC', n_channel_in=1, n_channel_out=1, n_dim=3, probabilistic=False, train_batch_size=1, train_checkpoint='weights_best.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_epochs=100, train_learning_rate=0.0001, train_loss='mse', train_reduce_lr={'patience': 5, 'factor': 0.5}, train_steps_per_epoch=400, train_tensorboard=True, unet_input_shape=(None, None, None, 1), unet_kern_size=3, unet_last_activation='linear', unet_n_depth=3, unet_n_first=48, unet_residual=True)\n"],"name":"stdout"},{"output_type":"stream","text":["base_model.py (148): output path for model already exists, files may be overwritten: /content/drive/My Drive/data/UNETVolumeSeg\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b5098e170>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c320>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0> and will run it as-is.\n","Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x7f4b4e68c4d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n","Match 0:\n","(lambda x: K.mean(x, axis=(- 1)))\n","\n","Match 1:\n","(lambda x: x)\n","\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","  6/400 [..............................] - ETA: 1:44 - loss: 0.0234 - mse: 0.0234 - mae: 0.0525WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0743s vs `on_train_batch_end` time: 0.1590s). Check your callbacks.\n","179/400 [============>.................] - ETA: 58s - loss: 0.0180 - mse: 0.0180 - mae: 0.0525"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IRT1VPzqhPZj","executionInfo":{"status":"aborted","timestamp":1621780093816,"user_tz":-120,"elapsed":8,"user":{"displayName":"Varun Kapoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqCnniCLExJES-Fu4_UKVqnr_f5QvFwiYQbkxVIYk=s64","userId":"00394081441130681785"}}},"source":[""],"execution_count":null,"outputs":[]}]}